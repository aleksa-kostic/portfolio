---
title: "Posterior Approximation for Normal Normal Using Markov Chains"
author: "Aleksa Kostic"
date: "2/20/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(bayesplot)
library(bayesrules)
library(tidyverse)
library(rstan)
```

## Model

$$
Y_i | \mu \sim N(\mu, 1.3^2) \\
\mu \sim N(10, 1.2^2)
$$

Suppose that on n = 4 independent observations, you observe $(Y_1,Y_2,Y_3,Y_4) = (7.1, 8.9, 8.4, 8.6)$

```{r}
nn_model <- "
data{
  real Y[4];
}
parameters {
  real mu;
}
model{
  mu ~ normal(10, 1.2);
  Y ~ normal(mu, 1.3);
}
"
```

```{r}
nn_sim  <- stan(
  model_code = nn_model, data = list(Y = c(7.1, 8.9, 8.4, 8.6)),
  chains = 4, iter = 5000*2, seed = 84735, refresh = FALSE
)
```

## Checking for convergence and consistency

```{r}
mcmc_trace(nn_sim, pars="mu", size = 0.1)
```

```{r}
mcmc_dens_overlay(nn_sim, pars = "mu") +
  ylab("density")
```

The most plausible value of mu seems to be at around 8.8. 

## Checking that the formula basis for the posterior matches the simulation (which is pretty close)

```{r}
summarize_normal_normal(mean = 10, sd = 1.2, sigma = sd(c(7.1, 8.9, 8.4, 8.6)), y_bar = mean(c(7.1, 8.9, 8.4, 8.6)), n = 4)
```

$\mu|Y_i \sim \mathcal{N}(8.422535, 0.3767915^2)$

